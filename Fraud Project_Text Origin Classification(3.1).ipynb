{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd6dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84233ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: nltk\n",
      "Version: 3.8.1\n",
      "Summary: Natural Language Toolkit\n",
      "Home-page: https://www.nltk.org/\n",
      "Author: NLTK Team\n",
      "Author-email: nltk.team@gmail.com\n",
      "License: Apache License, Version 2.0\n",
      "Location: C:\\ProgramData\\anaconda3\\Lib\\site-packages\n",
      "Requires: click, joblib, regex, tqdm\n",
      "Required-by: textblob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip show nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8572f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca72fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                                url  \\\n",
      "0  63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n",
      "1    279621        https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n",
      "2    287229  https://en.wikipedia.org/wiki/Inverse%20functi...   \n",
      "3  26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n",
      "4  38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n",
      "\n",
      "                      title  \\\n",
      "0    Sexhow railway station   \n",
      "1                  Etiäinen   \n",
      "2  Inverse function theorem   \n",
      "3         Stepping on Roses   \n",
      "4               Rob Bradley   \n",
      "\n",
      "                                          wiki_intro  \\\n",
      "0  Sexhow railway station was a railway station b...   \n",
      "1  In Finnish folklore, all places and things, an...   \n",
      "2  In mathematics, specifically differential calc...   \n",
      "3  is a Japanese shōjo manga series written and i...   \n",
      "4  Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n",
      "\n",
      "                                     generated_intro  title_len  \\\n",
      "0  Sexhow railway station was a railway station l...          3   \n",
      "1  In Finnish folklore, all places and things, an...          1   \n",
      "2  In mathematics, specifically differential calc...          3   \n",
      "3  is a Japanese shōjo manga series written and i...          3   \n",
      "4  Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n",
      "\n",
      "   wiki_intro_len  generated_intro_len  \\\n",
      "0             174                   78   \n",
      "1             187                   80   \n",
      "2             170                   59   \n",
      "3             335                  121   \n",
      "4             170                  136   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  200 word wikipedia style introduction on 'Sexh...   \n",
      "1  200 word wikipedia style introduction on 'Etiä...   \n",
      "2  200 word wikipedia style introduction on 'Inve...   \n",
      "3  200 word wikipedia style introduction on 'Step...   \n",
      "4  200 word wikipedia style introduction on 'Rob ...   \n",
      "\n",
      "                                      generated_text  prompt_tokens  \\\n",
      "0   located in the town of Sexhow, on the Cumbria...             25   \n",
      "1   animate or inanimate, have a spirit or \"etiäi...             26   \n",
      "2   function theorem states that for every real-v...             26   \n",
      "3   and illustrated by Maki Fujii. The series fol...             26   \n",
      "4   29, 1973) is an American former professional ...             28   \n",
      "\n",
      "   generated_text_tokens  \n",
      "0                     88  \n",
      "1                    101  \n",
      "2                     65  \n",
      "3                    150  \n",
      "4                    162  \n",
      "Index(['id', 'url', 'title', 'wiki_intro', 'generated_intro', 'title_len',\n",
      "       'wiki_intro_len', 'generated_intro_len', 'prompt', 'generated_text',\n",
      "       'prompt_tokens', 'generated_text_tokens'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\sruth\\Downloads\\Fraud Analytics_Project\\GPT-wiki-intro\\GPT-wiki-intro.csv\")\n",
    "\n",
    "# Display the first few rows and check for columns that might indicate human or AI-generated text\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3a2b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>wiki_intro</th>\n",
       "      <th>generated_intro</th>\n",
       "      <th>title_len</th>\n",
       "      <th>wiki_intro_len</th>\n",
       "      <th>generated_intro_len</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>generated_text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63064638</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sexhow%20railway...</td>\n",
       "      <td>Sexhow railway station</td>\n",
       "      <td>Sexhow railway station was a railway station b...</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>78</td>\n",
       "      <td>200 word wikipedia style introduction on 'Sexh...</td>\n",
       "      <td>located in the town of Sexhow, on the Cumbria...</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279621</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Eti%C3%A4inen</td>\n",
       "      <td>Etiäinen</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>80</td>\n",
       "      <td>200 word wikipedia style introduction on 'Etiä...</td>\n",
       "      <td>animate or inanimate, have a spirit or \"etiäi...</td>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287229</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Inverse%20functi...</td>\n",
       "      <td>Inverse function theorem</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>59</td>\n",
       "      <td>200 word wikipedia style introduction on 'Inve...</td>\n",
       "      <td>function theorem states that for every real-v...</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26712375</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stepping%20on%20...</td>\n",
       "      <td>Stepping on Roses</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>3</td>\n",
       "      <td>335</td>\n",
       "      <td>121</td>\n",
       "      <td>200 word wikipedia style introduction on 'Step...</td>\n",
       "      <td>and illustrated by Maki Fujii. The series fol...</td>\n",
       "      <td>26</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38894426</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Rob%20Bradley</td>\n",
       "      <td>Rob Bradley</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>136</td>\n",
       "      <td>200 word wikipedia style introduction on 'Rob ...</td>\n",
       "      <td>29, 1973) is an American former professional ...</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>44173767</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Randy%20Borum</td>\n",
       "      <td>Randy Borum</td>\n",
       "      <td>Randy Borum is a Professor and Coordinator of ...</td>\n",
       "      <td>Randy Borum is a Professor and Coordinator of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>71</td>\n",
       "      <td>200 word wikipedia style introduction on 'Rand...</td>\n",
       "      <td>of the Master of Fine Arts Program in Creativ...</td>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>33564134</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sa%27och%20language</td>\n",
       "      <td>Sa'och language</td>\n",
       "      <td>Sa'och (, also, \"Sauch\") is an endangered, nea...</td>\n",
       "      <td>Sa'och (, also, \"Sauch\") is an endangered, nuc...</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>134</td>\n",
       "      <td>200 word wikipedia style introduction on 'Sa'o...</td>\n",
       "      <td>nuclear-speaking, isolate language of the Ath...</td>\n",
       "      <td>33</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>4219548</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Philip%20Hanawalt</td>\n",
       "      <td>Philip Hanawalt</td>\n",
       "      <td>Philip C. Hanawalt (born 1931) is an American ...</td>\n",
       "      <td>Philip C. Hanawalt (born 1931) is an American ...</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>191</td>\n",
       "      <td>200 word wikipedia style introduction on 'Phil...</td>\n",
       "      <td>American graphic artist and illustrator. He i...</td>\n",
       "      <td>30</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2625970</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Vossius%20Gymnasium</td>\n",
       "      <td>Vossius Gymnasium</td>\n",
       "      <td>Vossius Gymnasium is a public gymnasium in Ams...</td>\n",
       "      <td>Vossius Gymnasium is a public gymnasium in the...</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>108</td>\n",
       "      <td>200 word wikipedia style introduction on 'Voss...</td>\n",
       "      <td>the town of Vossius, Netherlands. It is named...</td>\n",
       "      <td>32</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>32345102</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Simone%20Stratigo</td>\n",
       "      <td>Simone Stratigo</td>\n",
       "      <td>Simone Stratigo (, Symeon Filippos Stratigos; ...</td>\n",
       "      <td>Simone Stratigo (, Symeon Filippos Stratigos; ...</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>132</td>\n",
       "      <td>200 word wikipedia style introduction on 'Simo...</td>\n",
       "      <td>born 1 July 1979) is a Greek professional foo...</td>\n",
       "      <td>33</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                                url  \\\n",
       "0       63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n",
       "1         279621        https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n",
       "2         287229  https://en.wikipedia.org/wiki/Inverse%20functi...   \n",
       "3       26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n",
       "4       38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n",
       "...          ...                                                ...   \n",
       "149995  44173767        https://en.wikipedia.org/wiki/Randy%20Borum   \n",
       "149996  33564134  https://en.wikipedia.org/wiki/Sa%27och%20language   \n",
       "149997   4219548    https://en.wikipedia.org/wiki/Philip%20Hanawalt   \n",
       "149998   2625970  https://en.wikipedia.org/wiki/Vossius%20Gymnasium   \n",
       "149999  32345102    https://en.wikipedia.org/wiki/Simone%20Stratigo   \n",
       "\n",
       "                           title  \\\n",
       "0         Sexhow railway station   \n",
       "1                       Etiäinen   \n",
       "2       Inverse function theorem   \n",
       "3              Stepping on Roses   \n",
       "4                    Rob Bradley   \n",
       "...                          ...   \n",
       "149995               Randy Borum   \n",
       "149996           Sa'och language   \n",
       "149997           Philip Hanawalt   \n",
       "149998         Vossius Gymnasium   \n",
       "149999           Simone Stratigo   \n",
       "\n",
       "                                               wiki_intro  \\\n",
       "0       Sexhow railway station was a railway station b...   \n",
       "1       In Finnish folklore, all places and things, an...   \n",
       "2       In mathematics, specifically differential calc...   \n",
       "3       is a Japanese shōjo manga series written and i...   \n",
       "4       Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n",
       "...                                                   ...   \n",
       "149995  Randy Borum is a Professor and Coordinator of ...   \n",
       "149996  Sa'och (, also, \"Sauch\") is an endangered, nea...   \n",
       "149997  Philip C. Hanawalt (born 1931) is an American ...   \n",
       "149998  Vossius Gymnasium is a public gymnasium in Ams...   \n",
       "149999  Simone Stratigo (, Symeon Filippos Stratigos; ...   \n",
       "\n",
       "                                          generated_intro  title_len  \\\n",
       "0       Sexhow railway station was a railway station l...          3   \n",
       "1       In Finnish folklore, all places and things, an...          1   \n",
       "2       In mathematics, specifically differential calc...          3   \n",
       "3       is a Japanese shōjo manga series written and i...          3   \n",
       "4       Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n",
       "...                                                   ...        ...   \n",
       "149995  Randy Borum is a Professor and Coordinator of ...          2   \n",
       "149996  Sa'och (, also, \"Sauch\") is an endangered, nuc...          2   \n",
       "149997  Philip C. Hanawalt (born 1931) is an American ...          2   \n",
       "149998  Vossius Gymnasium is a public gymnasium in the...          2   \n",
       "149999  Simone Stratigo (, Symeon Filippos Stratigos; ...          2   \n",
       "\n",
       "        wiki_intro_len  generated_intro_len  \\\n",
       "0                  174                   78   \n",
       "1                  187                   80   \n",
       "2                  170                   59   \n",
       "3                  335                  121   \n",
       "4                  170                  136   \n",
       "...                ...                  ...   \n",
       "149995             185                   71   \n",
       "149996             175                  134   \n",
       "149997             166                  191   \n",
       "149998             168                  108   \n",
       "149999             153                  132   \n",
       "\n",
       "                                                   prompt  \\\n",
       "0       200 word wikipedia style introduction on 'Sexh...   \n",
       "1       200 word wikipedia style introduction on 'Etiä...   \n",
       "2       200 word wikipedia style introduction on 'Inve...   \n",
       "3       200 word wikipedia style introduction on 'Step...   \n",
       "4       200 word wikipedia style introduction on 'Rob ...   \n",
       "...                                                   ...   \n",
       "149995  200 word wikipedia style introduction on 'Rand...   \n",
       "149996  200 word wikipedia style introduction on 'Sa'o...   \n",
       "149997  200 word wikipedia style introduction on 'Phil...   \n",
       "149998  200 word wikipedia style introduction on 'Voss...   \n",
       "149999  200 word wikipedia style introduction on 'Simo...   \n",
       "\n",
       "                                           generated_text  prompt_tokens  \\\n",
       "0        located in the town of Sexhow, on the Cumbria...             25   \n",
       "1        animate or inanimate, have a spirit or \"etiäi...             26   \n",
       "2        function theorem states that for every real-v...             26   \n",
       "3        and illustrated by Maki Fujii. The series fol...             26   \n",
       "4        29, 1973) is an American former professional ...             28   \n",
       "...                                                   ...            ...   \n",
       "149995   of the Master of Fine Arts Program in Creativ...             25   \n",
       "149996   nuclear-speaking, isolate language of the Ath...             33   \n",
       "149997   American graphic artist and illustrator. He i...             30   \n",
       "149998   the town of Vossius, Netherlands. It is named...             32   \n",
       "149999   born 1 July 1979) is a Greek professional foo...             33   \n",
       "\n",
       "        generated_text_tokens  \n",
       "0                          88  \n",
       "1                         101  \n",
       "2                          65  \n",
       "3                         150  \n",
       "4                         162  \n",
       "...                       ...  \n",
       "149995                     92  \n",
       "149996                    184  \n",
       "149997                    272  \n",
       "149998                    147  \n",
       "149999                    173  \n",
       "\n",
       "[150000 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a09cd",
   "metadata": {},
   "source": [
    "### Labelling and Re-structuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8c8e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                     title  \\\n",
      "0  63064638    Sexhow railway station   \n",
      "1    279621                  Etiäinen   \n",
      "2    287229  Inverse function theorem   \n",
      "3  26712375         Stepping on Roses   \n",
      "4  38894426               Rob Bradley   \n",
      "\n",
      "                                                text label  \n",
      "0  Sexhow railway station was a railway station b...   HGT  \n",
      "1  In Finnish folklore, all places and things, an...   HGT  \n",
      "2  In mathematics, specifically differential calc...   HGT  \n",
      "3  is a Japanese shōjo manga series written and i...   HGT  \n",
      "4  Robert Milner \"Rob\" Bradley, Jr. (born August ...   HGT  \n"
     ]
    }
   ],
   "source": [
    "# Human-generated text\n",
    "human_texts = df[['id', 'title', 'wiki_intro']].copy()\n",
    "human_texts['label'] = 'HGT'  # Human Generated Text\n",
    "human_texts.rename(columns={'wiki_intro': 'text'}, inplace=True)  # Rename column to 'text'\n",
    "\n",
    "# Machine-generated text\n",
    "machine_texts = df[['id', 'title', 'generated_intro']].copy()\n",
    "machine_texts['label'] = 'MGT'  # Machine Generated Text\n",
    "machine_texts.rename(columns={'generated_intro': 'text'}, inplace=True)  # Rename column to 'text'\n",
    "\n",
    "# Combine both into a single DataFrame\n",
    "combined_df = pd.concat([human_texts, machine_texts], ignore_index=True)\n",
    "\n",
    "# Inspect the resulting DataFrame\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b038fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>63064638</td>\n",
       "      <td>Sexhow railway station</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150001</th>\n",
       "      <td>279621</td>\n",
       "      <td>Etiäinen</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150002</th>\n",
       "      <td>287229</td>\n",
       "      <td>Inverse function theorem</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150003</th>\n",
       "      <td>26712375</td>\n",
       "      <td>Stepping on Roses</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150004</th>\n",
       "      <td>38894426</td>\n",
       "      <td>Rob Bradley</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>44173767</td>\n",
       "      <td>Randy Borum</td>\n",
       "      <td>Randy Borum is a Professor and Coordinator of ...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>33564134</td>\n",
       "      <td>Sa'och language</td>\n",
       "      <td>Sa'och (, also, \"Sauch\") is an endangered, nuc...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>4219548</td>\n",
       "      <td>Philip Hanawalt</td>\n",
       "      <td>Philip C. Hanawalt (born 1931) is an American ...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>2625970</td>\n",
       "      <td>Vossius Gymnasium</td>\n",
       "      <td>Vossius Gymnasium is a public gymnasium in the...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>32345102</td>\n",
       "      <td>Simone Stratigo</td>\n",
       "      <td>Simone Stratigo (, Symeon Filippos Stratigos; ...</td>\n",
       "      <td>MGT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                     title  \\\n",
       "150000  63064638    Sexhow railway station   \n",
       "150001    279621                  Etiäinen   \n",
       "150002    287229  Inverse function theorem   \n",
       "150003  26712375         Stepping on Roses   \n",
       "150004  38894426               Rob Bradley   \n",
       "...          ...                       ...   \n",
       "299995  44173767               Randy Borum   \n",
       "299996  33564134           Sa'och language   \n",
       "299997   4219548           Philip Hanawalt   \n",
       "299998   2625970         Vossius Gymnasium   \n",
       "299999  32345102           Simone Stratigo   \n",
       "\n",
       "                                                     text label  \n",
       "150000  Sexhow railway station was a railway station l...   MGT  \n",
       "150001  In Finnish folklore, all places and things, an...   MGT  \n",
       "150002  In mathematics, specifically differential calc...   MGT  \n",
       "150003  is a Japanese shōjo manga series written and i...   MGT  \n",
       "150004  Robert Milner \"Rob\" Bradley, Jr. (born August ...   MGT  \n",
       "...                                                   ...   ...  \n",
       "299995  Randy Borum is a Professor and Coordinator of ...   MGT  \n",
       "299996  Sa'och (, also, \"Sauch\") is an endangered, nuc...   MGT  \n",
       "299997  Philip C. Hanawalt (born 1931) is an American ...   MGT  \n",
       "299998  Vossius Gymnasium is a public gymnasium in the...   MGT  \n",
       "299999  Simone Stratigo (, Symeon Filippos Stratigos; ...   MGT  \n",
       "\n",
       "[150000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgt_rows = combined_df[combined_df['label'] == 'MGT']\n",
    "mgt_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178c514",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d5cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sruth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sruth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d914825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenizing\n",
    "    words = word_tokenize(text)\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "combined_df['cleaned_text'] = combined_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee2aee",
   "metadata": {},
   "source": [
    "### Split dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df['cleaned_text']\n",
    "y = combined_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3392e9",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # You can adjust the max_features based on your needs\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2bf53",
   "metadata": {},
   "source": [
    "#### Use X_train_tfidf and X_test_tfidf for the model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specified models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, max_depth=5),\n",
    "}\n",
    "\n",
    "# Evaluate each model using a pipeline\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    \n",
    "    # Create a pipeline with TfidfVectorizer and the chosen model\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=500)),  # Use TF-IDF for feature extraction\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21c5c4",
   "metadata": {},
   "source": [
    "### NLP Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fb9ca",
   "metadata": {},
   "source": [
    "### Named-Entity Recognition: \n",
    "NER is an NLP technique that identifies and categorizes entities (specific elements) in text into predefined categories such as names of persons, organizations, locations, dates, times, quantities, monetary values, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Apply NER on a sample text\n",
    "sample_text = combined_df['text'].iloc[0]\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "# Extract and display entities\n",
    "for entity in doc.ents:\n",
    "    print(f\"Entity: {entity.text}, Label: {entity.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a2dda",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging:\n",
    "POS tagging is the process of assigning a grammatical category (such as noun, verb, adjective, etc.) to each word in a sentence. Each word is tagged based on its role in the sentence. POS tagging helps understand the structure and meaning of sentences by identifying how words function within them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and POS tag using spaCy\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "# Extract POS tags\n",
    "for token in doc:\n",
    "    print(f\"Word: {token.text}, POS: {token.pos_}, Tag: {token.tag_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef3ee",
   "metadata": {},
   "source": [
    "### Sentiment Analysis:\n",
    "Sentiment analysis determines the emotional tone behind a piece of text. It categorizes the text as positive, negative, or neutral, providing insights into opinions or attitudes expressed. \n",
    "\n",
    "Polarity (0.0903): This value ranges from -1 to 1, where -1 indicates a negative sentiment, 1 indicates a positive sentiment, and 0 represents a neutral sentiment. In this case, a polarity of 0.0903 suggests a slightly positive sentiment, but it's close to neutral.\n",
    "\n",
    "Subjectivity (0.3806): This value ranges from 0 to 1, where 0 indicates an objective statement (factual) and 1 represents a subjective statement (opinion-based). Here, the subjectivity score of 0.3806 suggests that the text is more objective but has some level of subjectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce00852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Apply sentiment analysis on a sample text\n",
    "blob = TextBlob(sample_text)\n",
    "print(f\"Sentiment Polarity: {blob.sentiment.polarity}, Subjectivity: {blob.sentiment.subjectivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cf0e7",
   "metadata": {},
   "source": [
    "### WordCloud: \n",
    "Visualize the most common words in both human-generated and machine-generated texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine human-generated and machine-generated texts\n",
    "human_texts = combined_df[combined_df['label'] == 'HGT']['cleaned_text']\n",
    "machine_texts = combined_df[combined_df['label'] == 'MGT']['cleaned_text']\n",
    "\n",
    "# Join the texts to form a single string for each category\n",
    "human_text_combined = ' '.join(human_texts)\n",
    "machine_text_combined = ' '.join(machine_texts)\n",
    "\n",
    "# Create a function to generate word cloud\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds for human-generated text\n",
    "generate_word_cloud(human_text_combined, 'Word Cloud for Human-Generated Text')\n",
    "\n",
    "# Generate word clouds for machine-generated text\n",
    "generate_word_cloud(machine_text_combined, 'Word Cloud for Machine-Generated Text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff08503",
   "metadata": {},
   "source": [
    "# HyperLink analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b787f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve and clean text from a URL\n",
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            texts = soup.find_all(text=True)\n",
    "            blacklist = ['style', 'script', 'head', 'title', 'meta', '[document]']\n",
    "            visible_texts = filter(lambda t: t.parent.name not in blacklist, texts)\n",
    "            text_content = u\" \".join(t.strip() for t in visible_texts)\n",
    "            text_content = re.sub(r'\\s+', ' ', text_content)  # Clean extra whitespace\n",
    "            return text_content\n",
    "        else:\n",
    "            print(f\"Failed to retrieve URL content. Status Code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract text from a News Article\n",
    "url = \"https://www.bbc.com/news/technology-56933733\"  # Replace this with an actual URL for testing\n",
    "extracted_text = extract_text_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function (extend as needed based on your notebook's logic)\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = text.lower()  # Example preprocessing (lowercasing)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the extracted text only if it's not None\n",
    "if extracted_text:\n",
    "    preprocessed_text = preprocess_text(extracted_text)\n",
    "    print(f\"Preprocessed Text: {preprocessed_text}\")\n",
    "else:\n",
    "    print(\"No text extracted from the URL. Cannot preprocess.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df140432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=500)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=50, max_depth=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dead8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting the pipeline, we do the prediction\n",
    "if preprocessed_text:\n",
    "    prediction = pipeline.predict([preprocessed_text])\n",
    "\n",
    "    # Interpret and print the result\n",
    "    result = \"Human Generated Text (HGT)\" if prediction == 0 else \"Machine Generated Text (MGT)\"\n",
    "    print(f\"Prediction: {result}\")\n",
    "else:\n",
    "    print(\"No text extracted from the URL to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3340c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
